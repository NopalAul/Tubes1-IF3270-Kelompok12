{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Import necessary libraries including NumPy, Matplotlib, scikit-learn for data, pickle for model saving/loading, networkx for visualization, and tqdm for progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from sklearn.preprocessing import StandardScaler  # For feature scaling\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into train/test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions Implementation\n",
    "Implement activation function classes including the base Activation class, Linear, ReLU, Sigmoid, Tanh, and Softmax, each with forward and derivative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions Implementation\n",
    "Implement loss function classes including the base Loss class, MSE (Mean Squared Error), BinaryCrossEntropy, and CategoricalCrossEntropy, each with forward and derivative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Initializers Implementation\n",
    "Implement weight initializer classes including the base Initializer class, ZeroInitializer, UniformInitializer, and NormalInitializer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Implementation\n",
    "Implement the Layer class with forward and backward propagation methods, weight initialization, and gradient updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN Model Implementation\n",
    "Implement the Feedforward Neural Network (FFNN) class with methods for creating the network, forward and backward propagation, weight updates, training, and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation on Dataset\n",
    "Load the dataset, preprocess it for classification, and train the FFNN model with appropriate hyperparameters. Evaluate model performance using accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import self-defined libraries\n",
    "from activation import ReLU, Sigmoid\n",
    "from initialization import NormalInitialization, UniformInitialization\n",
    "from loss import BinaryCrossEntropy\n",
    "from model import FFNN\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype(float)\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "# Convert to binary classification (0s vs 1s)\n",
    "mask = (y == 0) | (y == 1)\n",
    "X = X[mask]\n",
    "y = y[mask].to_numpy().reshape(-1, 1)  # Reshape target to match the expected input shape\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "layer_sizes=[784, 32, 16, 1]# Input layer, two hidden layers, and output layer\n",
    "activations = [ReLU(), ReLU(), Sigmoid()]  # Activation functions for each layer\n",
    "loss_function = BinaryCrossEntropy()  # Loss function for binary classification\n",
    "initializers = [NormalInitialization(mean=0, variance=0.1, seed=42), NormalInitialization(mean=0, variance=0.1, seed=42), UniformInitialization(seed=42)]  \n",
    "\n",
    "# Initialize the feedforward neural network\n",
    "model = FFNN(layer_sizes=layer_sizes, activations=activations, loss=loss_function, initializations=initializers)\n",
    "\n",
    "# Train the model\n",
    "history = model.train(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.01,\n",
    "    epochs=100,\n",
    "    x_y_val=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "accuracy = np.mean(y_pred_binary == y_test)  # Calculate accuracy\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ffnn_model.pkl\")\n",
    "\n",
    "# Load the model and verify its performance\n",
    "loaded_model = FFNN.load(\"ffnn_model.pkl\")\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "y_pred_loaded_binary = (y_pred_loaded > 0.5).astype(int)\n",
    "accuracy_loaded = np.mean(y_pred_loaded_binary == y_test)\n",
    "print(f\"Test accuracy (loaded model): {accuracy_loaded:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization\n",
    "Implement visualization of model architecture, training history, weight distributions, and gradient distributions using matplotlib and networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "model.plot_model()\n",
    "\n",
    "# Plot the training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot the weight distributions for all layers\n",
    "model.plot_weight_distribution()\n",
    "\n",
    "# Plot the gradient distributions for all layers\n",
    "model.plot_gradient_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model\n",
    "Demonstrate saving the trained model to disk and loading it back, then verify the loaded model produces identical predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save(\"ffnn_model.pkl\")\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = FFNN.load(\"ffnn_model.pkl\")\n",
    "\n",
    "# Verify that the loaded model produces identical predictions\n",
    "y_pred_original = model.predict(X_test)\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "\n",
    "# Check if predictions are identical\n",
    "identical_predictions = np.allclose(y_pred_original, y_pred_loaded)\n",
    "print(f\"Are predictions identical? {'Yes' if identical_predictions else 'No'}\")\n",
    "\n",
    "# Calculate accuracy for the loaded model\n",
    "y_pred_loaded_binary = (y_pred_loaded > 0.5).astype(int)\n",
    "accuracy_loaded = np.mean(y_pred_loaded_binary == y_test)\n",
    "print(f\"Test accuracy (loaded model): {accuracy_loaded:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
