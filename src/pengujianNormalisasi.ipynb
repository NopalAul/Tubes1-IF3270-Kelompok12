{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Import necessary libraries including NumPy, Matplotlib, scikit-learn for data, pickle for model saving/loading, networkx for visualization, and tqdm for progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation on Dataset\n",
    "Load the dataset, preprocess it for classification, and train the FFNN model with appropriate hyperparameters. Evaluate model performance using accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activation import Linear, ReLU, Sigmoid, Tanh, Softmax, LeakyReLU, ELU\n",
    "from loss import MeanSquaredError, BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from initialization import ZeroInitialization, UniformInitialization, NormalInitialization, XavierInitialization, HeInitialization\n",
    "from model import FFNN\n",
    "from rmsnorm import RMSNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Label butuh di-encode dengan One Hot\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:09<00:00, 6100.91it/s, train_loss=0.4252, val_loss=0.2901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:08<00:00, 6635.66it/s, train_loss=0.2305, val_loss=0.2353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:07<00:00, 7437.65it/s, train_loss=0.1817, val_loss=0.2054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8373.69it/s, train_loss=0.1515, val_loss=0.1856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8485.93it/s, train_loss=0.1292, val_loss=0.1729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8530.95it/s, train_loss=0.1124, val_loss=0.1622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8270.96it/s, train_loss=0.0993, val_loss=0.1584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8594.86it/s, train_loss=0.0889, val_loss=0.1468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8522.56it/s, train_loss=0.0796, val_loss=0.1453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8587.38it/s, train_loss=0.0716, val_loss=0.1414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8143.11it/s, train_loss=0.0647, val_loss=0.1382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8450.28it/s, train_loss=0.0593, val_loss=0.1351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8090.15it/s, train_loss=0.0539, val_loss=0.1351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8134.81it/s, train_loss=0.0495, val_loss=0.1340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:07<00:00, 7991.82it/s, train_loss=0.0455, val_loss=0.1332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:08<00:00, 6448.78it/s, train_loss=0.0418, val_loss=0.1333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:07<00:00, 7426.86it/s, train_loss=0.0383, val_loss=0.1310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8558.51it/s, train_loss=0.0349, val_loss=0.1322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8328.92it/s, train_loss=0.0326, val_loss=0.1325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56000/56000 [00:06<00:00, 8622.37it/s, train_loss=0.0297, val_loss=0.1344]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FFNN.__init__() got an unexpected keyword argument 'normalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     30\u001b[39m history_no_norm = model_no_norm.train(\n\u001b[32m     31\u001b[39m     x_train=X_train,\n\u001b[32m     32\u001b[39m     y_train=y_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     38\u001b[39m )\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Model dengan normalisasi RMS\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m model_norm = \u001b[43mFFNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitializations\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlistnormalisasi\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m history_norm = model_norm.train(\n\u001b[32m     50\u001b[39m     x_train=X_train,\n\u001b[32m     51\u001b[39m     y_train=y_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     57\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# plot loss tanpa normalisasi \u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: FFNN.__init__() got an unexpected keyword argument 'normalization'"
     ]
    }
   ],
   "source": [
    "layer_sizes = [784, 128, 32, 10]  # Fitur input ada 784\n",
    "\n",
    "activations = [\n",
    "    ELU(),\n",
    "    ELU(), \n",
    "    Softmax()     \n",
    "]\n",
    "\n",
    "loss_function = CategoricalCrossEntropy()\n",
    "\n",
    "initializations = [\n",
    "    HeInitialization(seed=42),  \n",
    "    XavierInitialization(seed=42),  \n",
    "    HeInitialization(seed=42)   \n",
    "]\n",
    "\n",
    "listnormalisasi = [\n",
    "    None,\n",
    "    RMSNorm,\n",
    "    None\n",
    "]\n",
    "\n",
    "model_no_norm = FFNN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=activations,\n",
    "    loss=loss_function,\n",
    "    initializations=initializations\n",
    ")\n",
    "\n",
    "history_no_norm = model_no_norm.train(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    epochs=20,\n",
    "    x_y_val=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Model dengan normalisasi RMS\n",
    "model_norm = FFNN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=activations,\n",
    "    loss=loss_function,\n",
    "    initializations=initializations,\n",
    "    normalization=listnormalisasi\n",
    ")\n",
    "\n",
    "history_norm = model_norm.train(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    epochs=20,\n",
    "    x_y_val=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# plot loss tanpa normalisasi \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_no_norm['train_loss'], label='Training Loss')\n",
    "plt.plot(history_norm['val_loss'], label='Validation Loss')\n",
    "plt.title('Train and Val Loss without Normalisasi')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# prediksi\n",
    "y_pred = model_no_norm.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "print(f\"Test accuracy without Normalization: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# plot loss dengan normalisasi RMS\n",
    "# plot loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_norm['train_loss'], label='Training Loss')\n",
    "plt.plot(history_norm['val_loss'], label='Validation Loss')\n",
    "plt.title('Train and Val Loss With RMS Normalization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# prediksi\n",
    "y_pred = model_norm.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_pred_classes == y_true_classes)\n",
    "print(f\"Test accuracy with L1: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization\n",
    "Implement visualization of model architecture, training history, weight distributions, and gradient distributions using matplotlib and networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribusi Bobot di tiap layer\n",
    "print(\"Bobot model tanpa normalisasi:\")\n",
    "model_no_norm.plot_weight_distribution()\n",
    "print(\"Bobot model dengan normalisasi RMS:\")\n",
    "model_norm.plot_weight_distribution()\n",
    "\n",
    "# Distribusi gradient di tiap layer\n",
    "print(\"Gradient model tanpa normalisasi:\")\n",
    "model_no_norm.plot_gradient_distribution()\n",
    "print(\"Gradient model dengan normalisasi RMS:\")\n",
    "model_norm.plot_gradient_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
